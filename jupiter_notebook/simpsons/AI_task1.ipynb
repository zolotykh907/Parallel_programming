{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e838ab-442f-4e49-bccb-4489f60f6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639835d6-6356-47b9-afa1-a4dfab8d2193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar  7 03:12:58 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           Off | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   27C    P0              54W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           Off | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   29C    P0              53W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           Off | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   25C    P0              51W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           Off | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   27C    P0              54W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abaea500-3940-437c-9290-3a096cb5e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import zipfile\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm_gui\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d0bb98-76c0-4dfe-94fc-908e6f3a83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5cff40-4653-4e8d-aa40-c426ba3e1d07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы: ['abraham_grampa_simpson', 'agnes_skinner', 'apu_nahasapeemapetilon', 'barney_gumble', 'bart_simpson', 'carl_carlson', 'charles_montgomery_burns', 'chief_wiggum', 'cletus_spuckler', 'comic_book_guy', 'disco_stu', 'edna_krabappel', 'fat_tony', 'gil', 'groundskeeper_willie', 'homer_simpson', 'kent_brockman', 'krusty_the_clown', 'lenny_leonard', 'lionel_hutz', 'lisa_simpson', 'maggie_simpson', 'marge_simpson', 'martin_prince', 'mayor_quimby', 'milhouse_van_houten', 'miss_hoover', 'moe_szyslak', 'ned_flanders', 'nelson_muntz', 'otto_mann', 'patty_bouvier', 'principal_skinner', 'professor_john_frink', 'rainier_wolfcastle', 'ralph_wiggum', 'selma_bouvier', 'sideshow_bob', 'sideshow_mel', 'snake_jailbird', 'troy_mcclure', 'waylon_smithers']\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "directory = 'simpsons_dataset/'\n",
    "classes = os.listdir(directory)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "data_dir = 'simpsons_dataset/'\n",
    "\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(\"Классы:\", dataset.classes)\n",
    "#print(\"Индексы классов:\", dataset.class_to_idx)\n",
    "print(len(dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3255fda8-4fe0-4721-8d4a-454e152badf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'kaggle_simpson_testset/kaggle_simpson_testset/'\n",
    "\n",
    "test_classes = []\n",
    "test_images = []\n",
    "\n",
    "def del_digit(img_name):\n",
    "  for char in img_name:\n",
    "    if char.isdigit():\n",
    "      img_name = img_name.replace(char, '')\n",
    "\n",
    "  clas = img_name[:-5]\n",
    "  test_classes.append(dataset.class_to_idx[clas])\n",
    "\n",
    "test_imgs = os.listdir(directory)\n",
    "for img in test_imgs:\n",
    "  image_path = directory + img\n",
    "  image = Image.open(image_path)\n",
    "  test_images.append(transform(image).unsqueeze(0))\n",
    "  del_digit(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63b1152b-1677-4c82-a511-580a43e82717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(My_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 32 * 32)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b31518-7ea1-426e-98d9-68c53d9e8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracy, val_accuracy = [], []\n",
    "\n",
    "model = My_CNN(num_classes = 42)\n",
    "model.cuda()\n",
    "\n",
    "def learning():\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "  val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "      images, labels = images.cuda(), labels.cuda()\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    train_loss = running_loss/len(train_dataloader)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss}, time = {epoch_time}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_running_loss / len(val_dataloader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "  torch.save(model.state_dict(), '/home/i.zolotykh/model_weights_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6d7097c-07ab-4da5-a464-e92bc6503cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.5482237339019775, time = 69.412513256073\n",
      "Validation Loss: 2.4819093704223634, Validation Accuracy: 0.33412944829233343\n",
      "Epoch 2/10, Loss: 1.8671886920928955, time = 66.94897770881653\n",
      "Validation Loss: 1.9465880870819092, Validation Accuracy: 0.4922378791497492\n",
      "Epoch 3/10, Loss: 1.4614568948745728, time = 66.37357544898987\n",
      "Validation Loss: 1.715474009513855, Validation Accuracy: 0.5524241700501552\n",
      "Epoch 4/10, Loss: 1.3725754022598267, time = 67.31366777420044\n",
      "Validation Loss: 1.52846417427063, Validation Accuracy: 0.6066395987580606\n",
      "Epoch 5/10, Loss: 0.992810070514679, time = 67.09694051742554\n",
      "Validation Loss: 1.4016777515411376, Validation Accuracy: 0.6384045856221638\n",
      "Epoch 6/10, Loss: 0.7035248875617981, time = 66.75250434875488\n",
      "Validation Loss: 1.3911816835403443, Validation Accuracy: 0.6460472892285646\n",
      "Epoch 7/10, Loss: 0.5026857852935791, time = 67.26816987991333\n",
      "Validation Loss: 1.327972912788391, Validation Accuracy: 0.6742297587771674\n",
      "Epoch 8/10, Loss: 0.34418734908103943, time = 66.32807302474976\n",
      "Validation Loss: 1.2933299541473389, Validation Accuracy: 0.7016957248626702\n",
      "Epoch 9/10, Loss: 0.26807549595832825, time = 66.7271683216095\n",
      "Validation Loss: 1.348781371116638, Validation Accuracy: 0.7081442560305709\n",
      "Epoch 10/10, Loss: 0.14680196344852448, time = 66.74850845336914\n",
      "Validation Loss: 1.4226284503936768, Validation Accuracy: 0.7148316216861715\n"
     ]
    }
   ],
   "source": [
    "learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f83e621b-bb16-48a5-b056-fcba1f34046a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = My_CNN(num_classes = 42).cuda()\n",
    "model.load_state_dict(torch.load('/home/i.zolotykh/model_weights_2.pth', map_location=torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3131fc3-412f-4e61-a8fd-30d09b2fccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9313131313131313\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "true = 0\n",
    "total = len(test_images)\n",
    "\n",
    "for image, label in zip(test_images, test_classes):\n",
    "    outputs = model(image.cuda())\n",
    "    if torch.argmax(outputs) == label:\n",
    "      true += 1\n",
    "\n",
    "print(true/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8285b02-6944-4d2c-bde4-3ac086383fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '045nelson.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "plt.imshow(image.resize((128,128)))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "input_image = transform(image).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    output = model(input_image.cuda())\n",
    "    output = np.argmax(output.detach().cpu().numpy())\n",
    "    print(dataset.classes[output])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e8db6a-232a-41df-b6a2-6715e1abd904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [tensor.detach().cpu().numpy() for tensor in train_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0828e-00ad-4629-b6ae-e235e78c4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721e501-fda4-48d7-9d21-b97f5997fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [epoch for epoch in range(num_epochs)]\n",
    "plt.plot(epochs, train_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train_Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c687a2e-f792-435f-b196-01db17191e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, val_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val_Losses')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
