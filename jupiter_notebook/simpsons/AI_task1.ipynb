{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32ad214-8b9e-4896-98b0-8ed7b6471e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639835d6-6356-47b9-afa1-a4dfab8d2193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 13 11:04:22 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           Off | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   27C    P0              54W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           Off | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   29C    P0              53W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           Off | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   25C    P0              51W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           Off | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              53W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abaea500-3940-437c-9290-3a096cb5e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import zipfile\n",
    "import shutil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm_gui\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import RandomVerticalFlip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d0bb98-76c0-4dfe-94fc-908e6f3a83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5cff40-4653-4e8d-aa40-c426ba3e1d07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "directory = 'simpsons_dataset/'\n",
    "classes = os.listdir(directory)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  #преобразует пиксели из диапазона [0,1] в диапазон [-1,1]\n",
    "])\n",
    "\n",
    "data_dir = 'simpsons_dataset/'\n",
    "\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(\"Классы:\", dataset.classes)\n",
    "\n",
    "print(len(dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3255fda8-4fe0-4721-8d4a-454e152badf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'kaggle_simpson_testset/kaggle_simpson_testset/'\n",
    "\n",
    "test_classes = []\n",
    "test_images = []\n",
    "\n",
    "def del_digit(img_name):\n",
    "  for char in img_name:\n",
    "    if char.isdigit():\n",
    "      img_name = img_name.replace(char, '')\n",
    "\n",
    "  clas = img_name[:-5]\n",
    "  test_classes.append(dataset.class_to_idx[clas])\n",
    "\n",
    "test_imgs = os.listdir(directory)\n",
    "for img in test_imgs:\n",
    "  image_path = directory + img\n",
    "  image = Image.open(image_path)\n",
    "  test_images.append(transform(image).unsqueeze(0))\n",
    "  del_digit(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b1152b-1677-4c82-a511-580a43e82717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(My_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 512)\n",
    "        #self.fc1 = nn.Linear(64 * 32 * 32, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 16 * 16)\n",
    "        #x = x.view(-1, 64 * 32 * 32)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b31518-7ea1-426e-98d9-68c53d9e8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "learning_rate = 0.001\n",
    "num_epochs = 13\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracy, val_accuracy = [], []\n",
    "\n",
    "model = My_CNN(num_classes = 42).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "def learning():\n",
    "  for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_dataloader:\n",
    "      images, labels = images.cuda(), labels.cuda()\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    train_loss = running_loss/len(train_dataloader)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {loss}, time = {epoch_time}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_running_loss / len(val_dataloader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d7097c-07ab-4da5-a464-e92bc6503cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee88fa-7385-49cf-916e-5e49b8b254f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_weights = 'weights/weigths_13ep_512n_128x128.pth'\n",
    "torch.save(model.state_dict(), path_to_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e621b-bb16-48a5-b056-fcba1f34046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = My_CNN(num_classes = 42).cuda()\n",
    "model.load_state_dict(torch.load(path_to_weights, map_location=torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3131fc3-412f-4e61-a8fd-30d09b2fccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "true = 0\n",
    "total = len(test_images)\n",
    "\n",
    "for image, label in zip(test_images, test_classes):\n",
    "    outputs = model(image.cuda())\n",
    "    if torch.argmax(outputs) == label:\n",
    "      true += 1\n",
    "\n",
    "test_accuracy = true/total\n",
    "\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8285b02-6944-4d2c-bde4-3ac086383fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(image):\n",
    "    image = Image.open(image)\n",
    "    \n",
    "    plt.imshow(image.resize((128,128)))\n",
    "    plt.show()\n",
    "    \n",
    "    input_image = transform(image).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = model(input_image.cuda())\n",
    "        output = np.argmax(output.detach().cpu().numpy())\n",
    "        print(dataset.classes[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e8db6a-232a-41df-b6a2-6715e1abd904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [tensor.detach().cpu().numpy() for tensor in train_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721e501-fda4-48d7-9d21-b97f5997fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_graphic = 'graphics/train_losses/train_losses_13e_512n_128x128.png'\n",
    "\n",
    "epochs = [epoch for epoch in range(num_epochs)]\n",
    "plt.plot(epochs, train_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train_Losses')\n",
    "plt.savefig(path_to_train_graphic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c687a2e-f792-435f-b196-01db17191e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_val_graphic = 'graphics/val_losses/val_losses_13e_512n_128x128.png'\n",
    "\n",
    "plt.plot(epochs, val_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val_Losses')\n",
    "plt.savefig(path_to_val_graphic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "688fa087-a9b5-473b-8ff9-683cfb07de32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/i.zolotykh\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
